{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA369 Y - T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filipe Antonio de Barros Reis - RA 091202\n",
    "<br>Lucas Brugnaro Badur - RA 094906"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre\n",
    "Projeto realizado para a disciplina de pós-graduação __IA369Y - Computação Afetiva__ oferecida pela Faculdade de Engenharia Elétrica (FEEC) da Universidade Estadual de Campinas (UNICAMP), lecionada pela professora Paula Dornhofer Paro Costa. \n",
    "\n",
    "### Aviso\n",
    "\n",
    "Este projeto tem como objetivo explorar possibilidades de processamento de linguagem natural para o português brasileiro. Todas as abordagens visam maximizar o aprendizado e a compreensão dos métodos utilizados, e não a performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Duas propostas foram disponibilizadas para esse projeto, a de classificar valência de manchetes brasileiras disponibilizadas em um conjunto de dados e a de atribuir intensidade de diferentes sentimentos a manchetes americanas.\n",
    "<br>A primeira opção foi a escolhida pelos autores devido à sua complexidade relacionada à diminuta disponibilidade de corpus e referências para o processamento de linguagem natural no idioma Português Brasileiro.\n",
    "<br>Com isso, este projeto tem como objetivo servir como uma referência básica para o processamento de linguagem natural em português, utilizando como uma alternativa viável a tradução para o inglês, já que para manchetes curtas e sentenças simples a tradução é mais do que adequada, sem comprometer o sentimento geral na maioria dos casos.\n",
    "    \n",
    "Além das dificuldades impostas pelo idioma, existe uma dificuldade inerente à tarefa de analisar valência em manchetes, já que elas são idealmente imparciais, dado o comprometimento ético e com neutralidade que a mídia jornalística deveria apresentar. Por outro lado, ao julgar a valência da manchete, o leitor tipicamente associa seu conteúdo às suas vivências anteriores e visão de mundo.  \n",
    "    \n",
    "Esse projeto apresenta diferentes abordagens para o processamento de linguagem natural em português, bem como os pontos fortes e fracos de cada uma das abordagens utilizadas neste projeto. Por fim, também são apresentadas abordagens para um classificador de origem do jornal e análises de qual das publicações obteve resultados mais neutros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagens adotadas\n",
    "Nesse projeto, três abordagens foram consideradas:\n",
    "- Tradução do banco de manchetes para inglês e uso da biblioteca TextBlob: essa estratégia foi considerada dada sua simplicidade e facilidade de implementação, sendo ótima para um trabalho inicial;\n",
    "- Avaliação de sentenças baseada em unigramas utilizando tanto o léxico em português Sentilex, quanto traduzindo e considerando o SentiWordNet;\n",
    "- Avaliação de sentenças inteiras em inglês, utilizando o módulo Vader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True #Turning the autocomplete on\n",
    "import nltk #used for text processing\n",
    "import pandas as pd #used for csv and matrix manipúlation\n",
    "import matplotlib as plt #used for data visualization\n",
    "import numpy as np #used for numerical application\n",
    "import os #used for folder checks\n",
    "import sys #used for folder checks\n",
    "from googletrans import Translator #translation lib\n",
    "from textblob import TextBlob #data processing lib\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #sentence sentiment analysis library\n",
    "import re #used for regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar lendo o arquivo csv processado utilizando regexp no editor SublimeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "originalDb = pd.read_csv(\"manchetesBrasildatabase/manchetesBrasildatabase.csv\", \n",
    "                         names=[\"Day\", \"Month\", \"Year\", \"Source\", \"Headline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações Gerais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação em sentenças"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma abordagem clássica da análise de textos é utilizar mecanismos para separá-los em sentenças e trabalhar com essas de forma independente. Como as manchetes são usualmente compostas por apenas uma sentença, não faremos nenhum tratamento para separação do texto em sentenças.\n",
    "<br>Na seção que utiliza a biblioteca TextBlob para análise, uma avaliação prévia nos demonstra que no caso de realizar uma separação em sentenças, apenas 7 manchetes seriam quebradas em mais de uma sentença."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translator + TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas abordagens de classificação diferem em sua essência, já que a por _Naive Bayes_ é baseada em um classificador treinado a partir de avaliações de filmes, contrastando com a utilizando a biblioteca _Pattern_ que é baseada em contagem de palavras utilizadas e sentimento associado a elas, com treinamento realizado a partir de avaliações de produtos.\n",
    "\n",
    "A documentação completa do TextBlob está disponível em: http://textblob.readthedocs.io/en/dev/advanced_usage.html\n",
    "<br>A documentação para o método _Pattern_ do TextBlob pode ser lida em: https://www.clips.uantwerpen.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES shrinks back to the level of 20 years ago'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC creates new monetary policy instrument.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Exchange generates word of mouth between AU a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indemnification to energy transmitters has al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>\"Politicians expect rapporteur to separate\" wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Day        Month  Year   Source  \\\n",
       "0           0    1  'fevereiro'  2017  'Valor'   \n",
       "1           1    1  'fevereiro'  2017  'Valor'   \n",
       "2           2    1  'fevereiro'  2017  'Valor'   \n",
       "3           3    1  'fevereiro'  2017  'Valor'   \n",
       "4           4    1  'fevereiro'  2017  'Valor'   \n",
       "\n",
       "                                            Headline  \n",
       "0  'BNDES shrinks back to the level of 20 years ago'  \n",
       "1       'BC creates new monetary policy instrument.'  \n",
       "2  'Exchange generates word of mouth between AU a...  \n",
       "3  'Indemnification to energy transmitters has al...  \n",
       "4  \"Politicians expect rapporteur to separate\" wh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translator = Translator()\n",
    "translated = []\n",
    "if os.path.isfile('translated.csv'):\n",
    "    translatedDb = pd.read_csv('translated.csv', encoding='latin-1')\n",
    "else:\n",
    "    for element in originalDb.Headline:\n",
    "        currentTranslation = translator.translate(element) \n",
    "        sys.stdout.write(\"\\r\" + currentTranslation.text)\n",
    "        sys.stdout.flush()\n",
    "        translated.append(currentTranslation.text)\n",
    "        \n",
    "    translatedDb = originalDb\n",
    "    translatedDb[\"THeadline\"] = translated\n",
    "    translatedDb.to_csv('translated.csv')\n",
    "    \n",
    "display (translatedDb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliar se as manchetes devem ser separadas por sentenças, vamos contar o total de sentenças e comparar com o total de manchetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentenças: 507 \n",
      "Manchetes: 500\n"
     ]
    }
   ],
   "source": [
    "sentencesCount = 0\n",
    "for headline in translatedDb.Headline:\n",
    "        analysis = TextBlob(headline )\n",
    "        sentencesCount += len(analysis.sentences)\n",
    "print(\"Sentenças: {0} \\nManchetes: {1}\".format(sentencesCount, len(translatedDb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o número de sentenças excede o de manchetes em apenas 7 unidades, é justificável não realizarmos essa separação dada a complexidade adicionada ao processo e o reduzido ganho.\n",
    "\n",
    "Agora podemos partir para a classificação das manchetes. Como já mencionado, essa biblioteca disponibiliza duas opções de análise de sentimentos:\n",
    "- Pattern: biblioteca que implementa a análise de sentimento utilizando um lexicon composto por palavras recorrentes em análises de produtos, anotadas de acordo com sua polaridade e subjetividade;\n",
    "- Naive Bayes: implementação do algoritmo de _Naive Bayes_ implementado pela biblioteca __nltk__ e treinado com uma base de dados de avaliações de filmes. Um ponto bastante negativo dessa implementação (ou ao menos do formato que utilizamos) é que o classificador é treinado novamente para cada frase considerada, exigindo um longo tempo de execução. \n",
    "\n",
    "A fim de evitar processamentos adicionais descecessários, implementamos o bloco abaixo que verifica se as machetes já foram processadas em algum momento e caso já tenham sido, apenas carrega os resultados para agilizar a execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('translated_bayes.csv'):\n",
    "    translatedDb = pd.read_csv('translated_bayes.csv', encoding='latin-1', index_col=0)\n",
    "else:\n",
    "    sentiments = []\n",
    "    for headline in translatedDb.Headline:\n",
    "        analysis = TextBlob(headline )\n",
    "        sys.stdout.write(\"\\r\" + headline + str(analysis.sentiment))\n",
    "        sys.stdout.flush()\n",
    "        sentiments.append(analysis.sentiment)\n",
    "    translatedDb['BlobSentimentsP']= sentiments\n",
    "    print('\\n\\n\\n*******Finished Pattern method, Starting Naive Bayes\\n This may take a while.')\n",
    "    sentiments = []\n",
    "    for headline in translatedDb.Headline:\n",
    "        analysis = TextBlob(headline, analyzer=NaiveBayesAnalyzer() )\n",
    "        sys.stdout.write(\"\\r\" + headline + str(analysis.sentiment))\n",
    "        sys.stdout.flush()\n",
    "        sentiments.append(analysis.sentiment)\n",
    "    translatedDb['BlobSentimentsNB']= sentiments\n",
    "    print (len(translatedDb))\n",
    "    translatedDb.head()\n",
    "    translatedDb.to_csv('translated_bayes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para facilitar a visualização de alguns resultados, podemos ordenar por ordem de magnitude dos sentimentos calculados utilizando a biblioteca pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>BlobSentimentsP</th>\n",
       "      <th>BlobSentimentsNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>14</td>\n",
       "      <td>'junho'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Folha'</td>\n",
       "      <td>'STF must judge Aecio's arrest warrant on the ...</td>\n",
       "      <td>Sentiment(polarity=-0.025, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='neg', p_pos=0.237896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>374</td>\n",
       "      <td>17</td>\n",
       "      <td>'janeiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Prison under arrest has been imprisoned outsi...</td>\n",
       "      <td>Sentiment(polarity=-0.025, subjectivity=0.025)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.853506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>15</td>\n",
       "      <td>'março'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Folha'</td>\n",
       "      <td>'Former president testifies and says he is the...</td>\n",
       "      <td>Sentiment(polarity=-0.037500000000000006, subj...</td>\n",
       "      <td>Sentiment(classification='neg', p_pos=0.433073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>'julho'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Government studies other measures for social ...</td>\n",
       "      <td>Sentiment(polarity=-0.04583333333333334, subje...</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.952242...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>'junho'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Marcus Aurelius will take Aetius' arrest requ...</td>\n",
       "      <td>Sentiment(polarity=-0.05, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.940510...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Day      Month  Year   Source  \\\n",
       "248           248   14    'junho'  2017  'Folha'   \n",
       "374           374   17  'janeiro'  2017  'Globo'   \n",
       "329           329   15    'março'  2017  'Folha'   \n",
       "203           203    3    'julho'  2017  'Valor'   \n",
       "64             64    1    'junho'  2017  'Globo'   \n",
       "\n",
       "                                              Headline  \\\n",
       "248  'STF must judge Aecio's arrest warrant on the ...   \n",
       "374  'Prison under arrest has been imprisoned outsi...   \n",
       "329  'Former president testifies and says he is the...   \n",
       "203  'Government studies other measures for social ...   \n",
       "64   'Marcus Aurelius will take Aetius' arrest requ...   \n",
       "\n",
       "                                       BlobSentimentsP  \\\n",
       "248       Sentiment(polarity=-0.025, subjectivity=0.0)   \n",
       "374     Sentiment(polarity=-0.025, subjectivity=0.025)   \n",
       "329  Sentiment(polarity=-0.037500000000000006, subj...   \n",
       "203  Sentiment(polarity=-0.04583333333333334, subje...   \n",
       "64         Sentiment(polarity=-0.05, subjectivity=0.0)   \n",
       "\n",
       "                                      BlobSentimentsNB  \n",
       "248  Sentiment(classification='neg', p_pos=0.237896...  \n",
       "374  Sentiment(classification='pos', p_pos=0.853506...  \n",
       "329  Sentiment(classification='neg', p_pos=0.433073...  \n",
       "203  Sentiment(classification='pos', p_pos=0.952242...  \n",
       "64   Sentiment(classification='pos', p_pos=0.940510...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Highest: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>BlobSentimentsP</th>\n",
       "      <th>BlobSentimentsNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Fachin will be able to go to a class that thi...</td>\n",
       "      <td>Sentiment(polarity=0.5, subjectivity=0.625)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.746054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>17</td>\n",
       "      <td>'janeiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Estado'</td>\n",
       "      <td>'Executives are confident but do not intend to...</td>\n",
       "      <td>Sentiment(polarity=0.5, subjectivity=0.8333333...</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.732663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>'março'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Estado'</td>\n",
       "      <td>'Tatuapé celebrates an unprecedented title.'</td>\n",
       "      <td>Sentiment(polarity=0.6, subjectivity=0.9)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.564443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>23</td>\n",
       "      <td>'agosto'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Estado'</td>\n",
       "      <td>'The 30 Best Series of All Time According to R...</td>\n",
       "      <td>Sentiment(polarity=1.0, subjectivity=0.3)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.589663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>23</td>\n",
       "      <td>'agosto'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Estado'</td>\n",
       "      <td>'BBC chooses the 100 best comedies of all time.'</td>\n",
       "      <td>Sentiment(polarity=1.0, subjectivity=0.3)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.664478...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Day        Month  Year    Source  \\\n",
       "7               7    1  'fevereiro'  2017   'Globo'   \n",
       "390           390   17    'janeiro'  2017  'Estado'   \n",
       "51             51    1      'março'  2017  'Estado'   \n",
       "456           456   23     'agosto'  2017  'Estado'   \n",
       "458           458   23     'agosto'  2017  'Estado'   \n",
       "\n",
       "                                              Headline  \\\n",
       "7    'Fachin will be able to go to a class that thi...   \n",
       "390  'Executives are confident but do not intend to...   \n",
       "51        'Tatuapé celebrates an unprecedented title.'   \n",
       "456  'The 30 Best Series of All Time According to R...   \n",
       "458   'BBC chooses the 100 best comedies of all time.'   \n",
       "\n",
       "                                       BlobSentimentsP  \\\n",
       "7          Sentiment(polarity=0.5, subjectivity=0.625)   \n",
       "390  Sentiment(polarity=0.5, subjectivity=0.8333333...   \n",
       "51           Sentiment(polarity=0.6, subjectivity=0.9)   \n",
       "456          Sentiment(polarity=1.0, subjectivity=0.3)   \n",
       "458          Sentiment(polarity=1.0, subjectivity=0.3)   \n",
       "\n",
       "                                      BlobSentimentsNB  \n",
       "7    Sentiment(classification='pos', p_pos=0.746054...  \n",
       "390  Sentiment(classification='pos', p_pos=0.732663...  \n",
       "51   Sentiment(classification='pos', p_pos=0.564443...  \n",
       "456  Sentiment(classification='pos', p_pos=0.589663...  \n",
       "458  Sentiment(classification='pos', p_pos=0.664478...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trnsSorted = translatedDb.sort_values(['BlobSentimentsP'])\n",
    "print(\"Lowest: \\n\")\n",
    "display(trnsSorted.head(5))\n",
    "print(\"\\n\\n\\nHighest: \\n\")\n",
    "display(trnsSorted.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível percebermos que o resultado muda do método Pattern para o Naive Bayes. Um exemplo claro dessa variação é encontrado na linha 374, onde a manchete \"Prisão rebelada tem presos fora das celas desde 2015.\" foi classificada como negativa pelo Pattern e positiva pelo NaiveBayes. Uma possível justificativa para isso é que palavras como \"rebelada\", \"prisão\" e \"celas\" podem estar relacionadas a filmes bons, mas não possuem relação com bons produtos.\n",
    "A análise detalhada e comparação aprofundada dos resultados pode ser encontrada na seção Resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bag of Words + SentiLex\n",
    "\n",
    "Nessa abordagem utilizamos o SentiLex-PT01, que é um léxico de sentimentos para o português de portugal criado pela Universidade de Lisboa e formado por 6.321 palavras. Para a utilização de léxico, adotamos a abordagem de reduzir as manchetes a grupos de palavras individuais, remover as _stopwords_, classificar essas palavras de forma individual e avaliar a valência da frase tomando por base o conjunto de pontuações individuais. \n",
    "<br>Para isso, iniciamos carregando o léxico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>GN</th>\n",
       "      <th>TG</th>\n",
       "      <th>Pol</th>\n",
       "      <th>Anot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abafado.PoS=Adj</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>POL=-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafante.PoS=Adj</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>POL=-1</td>\n",
       "      <td>ANOT=MAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaixado.PoS=Adj</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>POL=-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalado.PoS=Adj</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>POL=-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalizado.PoS=Adj</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>POL=1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word     GN      TG     Pol       Anot\n",
       "0    abafado.PoS=Adj  GN=ms  TG=HUM  POL=-1  ANOT=JALC\n",
       "1   abafante.PoS=Adj  GN=ms  TG=HUM  POL=-1   ANOT=MAN\n",
       "2   abaixado.PoS=Adj  GN=ms  TG=HUM  POL=-1  ANOT=JALC\n",
       "3    abalado.PoS=Adj  GN=ms  TG=HUM  POL=-1  ANOT=JALC\n",
       "4  abalizado.PoS=Adj  GN=ms  TG=HUM   POL=1  ANOT=JALC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiLex = pd.read_csv('SentiLex-PT01/SentiLex-lem-PT01.txt', sep = ';', names=['Word', 'GN', \"TG\", \"Pol\", \"Anot\"])\n",
    "display(sentiLex.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o arquivo carregado está com as informações e formatação padrão do léxico, precisamos adequá-lo ao nosso uso. Para tanto, podemos remover a função gramatical associada às palavras e o indicador POL= do campo de polaridade das mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>GN</th>\n",
       "      <th>TG</th>\n",
       "      <th>Pol</th>\n",
       "      <th>Anot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abafado</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafante</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>-1</td>\n",
       "      <td>ANOT=MAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaixado</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalado</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>-1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalizado</td>\n",
       "      <td>GN=ms</td>\n",
       "      <td>TG=HUM</td>\n",
       "      <td>1</td>\n",
       "      <td>ANOT=JALC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word     GN      TG Pol       Anot\n",
       "0    abafado  GN=ms  TG=HUM  -1  ANOT=JALC\n",
       "1   abafante  GN=ms  TG=HUM  -1   ANOT=MAN\n",
       "2   abaixado  GN=ms  TG=HUM  -1  ANOT=JALC\n",
       "3    abalado  GN=ms  TG=HUM  -1  ANOT=JALC\n",
       "4  abalizado  GN=ms  TG=HUM   1  ANOT=JALC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newWords = []\n",
    "newPols= []\n",
    "for line in sentiLex.Word:\n",
    "    newWords.append(line.replace('.PoS=Adj',''))\n",
    "for line in sentiLex.Pol:\n",
    "    newPols.append(line.replace('POL=',''))\n",
    "\n",
    "sentiLex.Word = newWords\n",
    "sentiLex.Pol = newPols\n",
    "display(sentiLex.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos uma base no formato desejado. \n",
    "\n",
    "O próximo passo é preparar nossas manchetes para a análise. Para tanto, podemos remover alguns caracteres não-importantes, como numerais. Os demais caracteres especiais também podem ser removidos, mas o tratamento para remover apenas caracteres especiais excluindo pontuações do escopo do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES encolhe e volta ao nível de 20 anos atrás'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC cria novo instrumento de política monetária.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Câmbio gera bate-boca entre UA e UE.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indenização a transmissoras de energia já che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Políticos esperam que relator separe \"joio do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day        Month  Year   Source  \\\n",
       "0    1  'fevereiro'  2017  'Valor'   \n",
       "1    1  'fevereiro'  2017  'Valor'   \n",
       "2    1  'fevereiro'  2017  'Valor'   \n",
       "3    1  'fevereiro'  2017  'Valor'   \n",
       "4    1  'fevereiro'  2017  'Valor'   \n",
       "\n",
       "                                            Headline  \n",
       "0  'BNDES encolhe e volta ao nível de 20 anos atrás'  \n",
       "1  'BC cria novo instrumento de política monetária.'  \n",
       "2             'Câmbio gera bate-boca entre UA e UE.'  \n",
       "3  'Indenização a transmissoras de energia já che...  \n",
       "4  'Políticos esperam que relator separe \"joio do...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bowDb = originalDb\n",
    "wordLines = []\n",
    "def rem_numbers(text):\n",
    "    for line in text:\n",
    "        wordLines.append(re.sub(\"[0-9]\",\" \", line))\n",
    "    return wordLines\n",
    "bowDb.CleanHeadline = rem_numbers(bowDb.Headline)\n",
    "display(bowDb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em sequência, podemos remover algumas palavras que não são relevantes para a análise, as _stopwords_. Para tanto, precisamos carregar esse conjunto disponível na biblioteca __nltk__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print (stopwords.words(\"portuguese\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as _stopwords_ carregadas, podemos percorrer as manchetes e manter apenas as palavras que não pertencerem a esse grupo indesejado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>CleanHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES encolhe e volta ao nível de 20 anos atrás'</td>\n",
       "      <td>'BNDES encolhe volta nível 20 anos atrás'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC cria novo instrumento de política monetária.'</td>\n",
       "      <td>'BC cria novo instrumento política monetária.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Câmbio gera bate-boca entre UA e UE.'</td>\n",
       "      <td>'Câmbio gera bate-boca UA UE.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indenização a transmissoras de energia já che...</td>\n",
       "      <td>'Indenização transmissoras energia chega tarif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Políticos esperam que relator separe \"joio do...</td>\n",
       "      <td>'Políticos esperam relator separe \"joio trigo\".'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day        Month  Year   Source  \\\n",
       "0    1  'fevereiro'  2017  'Valor'   \n",
       "1    1  'fevereiro'  2017  'Valor'   \n",
       "2    1  'fevereiro'  2017  'Valor'   \n",
       "3    1  'fevereiro'  2017  'Valor'   \n",
       "4    1  'fevereiro'  2017  'Valor'   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  'BNDES encolhe e volta ao nível de 20 anos atrás'   \n",
       "1  'BC cria novo instrumento de política monetária.'   \n",
       "2             'Câmbio gera bate-boca entre UA e UE.'   \n",
       "3  'Indenização a transmissoras de energia já che...   \n",
       "4  'Políticos esperam que relator separe \"joio do...   \n",
       "\n",
       "                                       CleanHeadline  \n",
       "0         'BNDES encolhe volta nível 20 anos atrás'   \n",
       "1    'BC cria novo instrumento política monetária.'   \n",
       "2                    'Câmbio gera bate-boca UA UE.'   \n",
       "3  'Indenização transmissoras energia chega tarif...  \n",
       "4  'Políticos esperam relator separe \"joio trigo\".'   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordLines = []\n",
    "\n",
    "for line in bowDb.Headline:\n",
    "    words = ''\n",
    "    for word in line.split():\n",
    "        if word not in stopwords.words(\"portuguese\"):\n",
    "            words = words + word + ' '\n",
    "    wordLines.append(words)\n",
    "    \n",
    "bowDb['CleanHeadline'] = wordLines\n",
    "display(bowDb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As frases ficam sem elementos de união, mas ainda transmitem seu completo sentido, como visto na primeira manchete, \"BNDES encolhe volta nível 20 anos atrás\".\n",
    "<br>Por fim, podemos analisar as palavras de todas as manchetes e obter a polaridade para cada uma das palavras presentes no léxico. Para as frases em que nenhuma palavra estiver contida no léxico, o número 0 é atribuído, enquanto que para as demais, um vetor contendo as pontuações é considerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>CleanHeadline</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES encolhe e volta ao nível de 20 anos atrás'</td>\n",
       "      <td>'BNDES encolhe volta nível 20 anos atrás'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC cria novo instrumento de política monetária.'</td>\n",
       "      <td>'BC cria novo instrumento política monetária.'</td>\n",
       "      <td>[[0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Câmbio gera bate-boca entre UA e UE.'</td>\n",
       "      <td>'Câmbio gera bate-boca UA UE.'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indenização a transmissoras de energia já che...</td>\n",
       "      <td>'Indenização transmissoras energia chega tarif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Políticos esperam que relator separe \"joio do...</td>\n",
       "      <td>'Políticos esperam relator separe \"joio trigo\".'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Philips quer administrar hospitais públicos n...</td>\n",
       "      <td>'Philips quer administrar hospitais públicos B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Com vendas em queda C&amp;amp;C muda lojas e troc...</td>\n",
       "      <td>'Com vendas queda C&amp;amp;C muda lojas troca dir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Fachin poderá ir para turma que julga Lava-Ja...</td>\n",
       "      <td>'Fachin poderá ir turma julga Lava-Jato.'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Eike tem multas que superam fundo para prisões.'</td>\n",
       "      <td>'Eike multas superam fundo prisões.'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Globo'</td>\n",
       "      <td>'Operador pagou decoração de luxo de imóveis d...</td>\n",
       "      <td>'Operador pagou decoração luxo imóveis Cabral.'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day        Month  Year   Source  \\\n",
       "0    1  'fevereiro'  2017  'Valor'   \n",
       "1    1  'fevereiro'  2017  'Valor'   \n",
       "2    1  'fevereiro'  2017  'Valor'   \n",
       "3    1  'fevereiro'  2017  'Valor'   \n",
       "4    1  'fevereiro'  2017  'Valor'   \n",
       "5    1  'fevereiro'  2017  'Valor'   \n",
       "6    1  'fevereiro'  2017  'Valor'   \n",
       "7    1  'fevereiro'  2017  'Globo'   \n",
       "8    1  'fevereiro'  2017  'Globo'   \n",
       "9    1  'fevereiro'  2017  'Globo'   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  'BNDES encolhe e volta ao nível de 20 anos atrás'   \n",
       "1  'BC cria novo instrumento de política monetária.'   \n",
       "2             'Câmbio gera bate-boca entre UA e UE.'   \n",
       "3  'Indenização a transmissoras de energia já che...   \n",
       "4  'Políticos esperam que relator separe \"joio do...   \n",
       "5  'Philips quer administrar hospitais públicos n...   \n",
       "6  'Com vendas em queda C&amp;C muda lojas e troc...   \n",
       "7  'Fachin poderá ir para turma que julga Lava-Ja...   \n",
       "8  'Eike tem multas que superam fundo para prisões.'   \n",
       "9  'Operador pagou decoração de luxo de imóveis d...   \n",
       "\n",
       "                                       CleanHeadline Scores  \n",
       "0         'BNDES encolhe volta nível 20 anos atrás'       0  \n",
       "1    'BC cria novo instrumento política monetária.'   [[0]]  \n",
       "2                    'Câmbio gera bate-boca UA UE.'       0  \n",
       "3  'Indenização transmissoras energia chega tarif...      0  \n",
       "4  'Políticos esperam relator separe \"joio trigo\".'       0  \n",
       "5  'Philips quer administrar hospitais públicos B...      0  \n",
       "6  'Com vendas queda C&amp;C muda lojas troca dir...      0  \n",
       "7         'Fachin poderá ir turma julga Lava-Jato.'       0  \n",
       "8              'Eike multas superam fundo prisões.'       0  \n",
       "9   'Operador pagou decoração luxo imóveis Cabral.'       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordScores = []\n",
    "lineScores = []\n",
    "lineScore = 0\n",
    "for line in bowDb.CleanHeadline:\n",
    "    words = ''\n",
    "    wordScores = []\n",
    "    for word in line.split():\n",
    "        correspWord = sentiLex[sentiLex.Word == word]\n",
    "        if not correspWord.empty:\n",
    "            wordScores.append(correspWord.Pol)\n",
    "            \n",
    "    if len(wordScores) != 0:\n",
    "        lineScores.append(wordScores)\n",
    "    else:\n",
    "        lineScores.append(0)\n",
    "bowDb['Scores'] = lineScores\n",
    "display(bowDb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho avaliado acima, poucas frases apresentam resultados. A impressão que temos é que o vocabulário das manchetes é pouco representado no léxico. Para confirmar essa impressão, podemos montar o vocabulário das manchetes e comparar com o léxico. \n",
    "<br>Para essa operação, utilizamos o módulo _count vectorizer_ da biblioteca __scikit-learn__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1633)\n",
      "['abandonar', 'aberto', 'abertos', 'abertura', 'abilio', 'abismo', 'aborto', 'abre', 'abrigo', 'abrir', 'abuso', 'aceita', 'acelerar', 'acena', 'achaques', 'acidentes', 'acima', 'acordo', 'aderiu', 'adia', 'adiado', 'adiante', 'adiar', 'administrar', 'admite', 'admitiu', 'adriana', 'aeronáutica', 'aeroporto', 'afaga', 'afasta', 'afastar', 'afastou', 'afeta', 'afetar', 'afirma', 'agenda', 'agentes', 'agido', 'agora', 'agradar', 'agressão', 'agronegócio', 'ajudará', 'ajuste', 'al', 'ala', 'alas', 'alavanca', 'alcance', 'alckmista', 'alegorias', 'alemanha', 'aleppo', 'alerta', 'alguns', 'aliados', 'aloysio', 'alta', 'alternativa', 'alternativas', 'alto', 'altruísmo', 'aluguel', 'além', 'alíquota', 'amanhã', 'amarela', 'ameaça', 'ameaçou', 'amenizam', 'americana', 'americano', 'amil', 'amizade', 'amor', 'amp', 'amplia', 'américa', 'analistas', 'anatel', 'ancelmo', 'andrade', 'andreas', 'ano', 'anos', 'ansiedade', 'antes', 'anticorrupção', 'anuncia', 'anvisa', 'análises', 'anúncio', 'ao', 'aos', 'apertos', 'apoia', 'apoiam', 'apoio', 'aponta', 'apontada', 'aposentado', 'aposentadoria', 'aposentadorias', 'aposta', 'aprova', 'aprovada', 'apurados', 'apuração', 'após', 'aquisições', 'armínio', 'arrecadar', 'arrecadação', 'articula', 'articulação', 'artificial', 'as', 'assad', 'assassinatos', 'assembleia', 'assume', 'assumem', 'assunção', 'ataca', 'atacarejo', 'ataque', 'ataques', 'atendimento', 'atentado', 'atibaia', 'atige', 'atinge', 'atirador', 'ativistas', 'atletas', 'ato', 'atores', 'atrai', 'atrasa', 'atraso', 'atribui', 'atrás', 'atual', 'atuação', 'atuou', 'até', 'aumenta', 'aumentam', 'aumentar', 'aumento', 'aurélio', 'austeridade', 'autorizam', 'auxiliares', 'avança', 'avanço', 'avanços', 'avesso', 'aviação', 'avisou', 'avião', 'azevêdo', 'azul', 'ações', 'açúcar', 'aécio', 'aéreo', 'aós', 'baixa', 'baixada', 'baixo', 'balcão', 'baleado', 'baleados', 'banco', 'bancosw', 'bangu', 'barata', 'barbosa', 'barrar', 'barreiras', 'barros', 'barroso', 'base', 'basquete', 'batalhas', 'batalhão', 'bate', 'bbc', 'bc', 'bebê', 'beijão', 'bens', 'bergamo', 'bernardo', 'bi', 'bilhões', 'blinda', 'blocos', 'bndes', 'boate', 'boca', 'boicotar', 'boicote', 'bolsas', 'bolsonaro', 'bomba', 'bosch', 'bradesco', 'brasil', 'brasileiros', 'braskem', 'brasília', 'braço', 'bruta', 'bueno', 'busca', 'cabral', 'cabul', 'cada', 'cadeia', 'caem', 'cai', 'cair', 'cairá', 'caixa', 'calamidade', 'calendário', 'canadá', 'candidato', 'candidatos', 'candidatura', 'canetadas', 'canções', 'capitais', 'capital', 'carceragem', 'cargo', 'cargos', 'carnaval', 'carne', 'carreira', 'cartão', 'carência', 'casa', 'caso', 'casos', 'cassar', 'castro', 'causa', 'caça', 'caí', 'cedae', 'cehab', 'celas', 'celso', 'cena', 'cenas', 'censor', 'censura', 'centrais', 'centro', 'cenário', 'ceo', 'ceos', 'cerimônia', 'certa', 'cervejaria', 'cesar', 'cesp', 'chaim', 'chance', 'chapa', 'chavismo', 'chefe', 'chefia', 'chega', 'chegar', 'chico', 'china', 'chineses', 'chinês', 'ciberataque', 'cibernético', 'cielo', 'cinco', 'cipro', 'cisão', 'cita', 'citado', 'citados', 'clero', 'clientes', 'clima', 'climático', 'clt', 'clube', 'clássico', 'cnn', 'cobra', 'cobrança', 'cobrar', 'cobre', 'coelho', 'colaboradores', 'colaborar', 'colega', 'coligações', 'colombiano', 'colômbia', 'com', 'comandar', 'comando', 'combustível', 'comemora', 'comgás', 'comissão', 'como', 'competição', 'comédias', 'comércio', 'conciliação', 'concorrente', 'condena', 'condenado', 'conectam', 'confiantes', 'confinadas', 'confirma', 'confisco', 'confissões', 'conflito', 'conflitos', 'confrontos', 'congela', 'congresso', 'conheça', 'conselheiro', 'conservador', 'constituinte', 'constrangedoras', 'construtoras', 'consulta', 'conta', 'contas', 'contatarem', 'contemporânea', 'contestação', 'contra', 'contrapartidas', 'contraria', 'contratar', 'contribuintes', 'controlar', 'controle', 'convence', 'convencer', 'converter', 'convoca', 'convocar', 'convovca', 'copa', 'coreia', 'corpo', 'corre', 'correa', 'corrupção', 'cortadas', 'cortar', 'corte', 'cortes', 'cosan', 'cracolândia', 'credores', 'cresce', 'crescem', 'crescer', 'cria', 'criam', 'crianças', 'crime', 'criou', 'crise', 'crises', 'critica', 'criticam', 'crivella', 'crédito', 'crítica', 'críticas', 'cuba', 'cunha', 'curricular', 'custaria', 'custará', 'cármen', 'câmara', 'câmbio', 'câncer', 'da', 'dada', 'dalasam', 'das', 'datas', 'de', 'debate', 'debater', 'declaração', 'decoração', 'decretam', 'decreto', 'decretos', 'decência', 'defende', 'defendem', 'defesa', 'define', 'definem', 'definirá', 'deflagra', 'deixa', 'deixam', 'deixar', 'deixará', 'deixou', 'delatar', 'delator', 'delatores', 'delação', 'delações', 'delfim', 'deloitte', 'demissão', 'demite', 'demoratas', 'dendê', 'dengue', 'denuncia', 'denúncia', 'depoimento', 'depoimentos', 'depois', 'depõe', 'derivado', 'derrubou', 'desalento', 'desapreço', 'descontos', 'desculpas', 'desde', 'desempate', 'desempregados', 'desemprego', 'desfigurar', 'desigualdade', 'desiste', 'desistir', 'desmedida', 'desmoralização', 'despejo', 'despesas', 'deu', 'deus', 'deve', 'devem', 'deveria', 'devolver', 'devolverá', 'dez', 'dia', 'dias', 'diferença', 'dificuldades', 'dificulta', 'difícil', 'dilma', 'diminuir', 'dinehiro', 'dinheiro', 'diniz', 'diplomacia', 'direito', 'diretas', 'diretoria', 'dirigente', 'dirigir', 'discurso', 'discórdias', 'dispara', 'dispersão', 'disputa', 'distante', 'distorce', 'distribuidoras', 'distúrbio', 'dita', 'divide', 'divulga', 'diz', 'dizem', 'do', 'doações', 'dobra', 'dobrar', 'dobro', 'dois', 'domingo', 'domus', 'dona', 'donald', 'dono', 'donos', 'doou', 'doria', 'dos', 'dpaschoal', 'drama', 'driblar', 'drogas', 'duro', 'dá', 'déficit', 'dívida', 'dólar', 'dúvidas', 'economia', 'economistas', 'econômica', 'editorial', 'edição', 'edson', 'educação', 'efeito', 'eficácia', 'eike', 'elege', 'eleitor', 'eleitores', 'eleição', 'eleições', 'eleva', 'elevam', 'elevar', 'elio', 'elmar', 'elétrica', 'elétrico', 'em', 'embaixada', 'embate', 'empate', 'empreendedor', 'emprego', 'empregos', 'empreiteiros', 'empresa', 'empresarial', 'empresas', 'empresários', 'encolhe', 'energia', 'enfarte', 'enfrentar', 'enfrentará', 'entidades', 'entra', 'entre', 'entrega', 'entrevista', 'equador', 'erdogan', 'escalão', 'escândalo', 'esgoto', 'esperam', 'esporte', 'esquerda', 'estacionamentos', 'estados', 'estagnado', 'estamos', 'estandarte', 'estatais', 'estrangeiro', 'estrangeiros', 'estratégia', 'estuda', 'estudam', 'está', 'estão', 'estée', 'esvazia', 'esvaziada', 'eua', 'eunício', 'europa', 'europol', 'evitar', 'evitavam', 'ex', 'exames', 'excessivos', 'executivo', 'executivos', 'execução', 'exigir', 'expansão', 'explicam', 'exportação', 'expulsar', 'expõe', 'exterior', 'extra', 'exército', 'fachin', 'facção', 'fala', 'falará', 'falha', 'falho', 'falsa', 'falsas', 'falta', 'famílias', 'fantasmas', 'farc', 'fase', 'favela', 'favelas', 'favoráveis', 'favorável', 'faz', 'fazenda', 'fazer', 'febre', 'federal', 'felipe', 'fere', 'ferem', 'feridos', 'fernando', 'ferrogrão', 'ferrovia', 'festival', 'fevereiro', 'fez', 'fgts', 'fica', 'fiel', 'fies', 'fiesp', 'fila', 'filha', 'filho', 'fim', 'final', 'financiamentos', 'finda', 'firma', 'fiscal', 'fiscalizar', 'fisco', 'fixa', 'flechas', 'fnac', 'foca', 'foi', 'folha', 'folia', 'fora', 'forma', 'foro', 'fortalecer', 'forte', 'força', 'fraca', 'fracassa', 'fraga', 'franco', 'frança', 'fraude', 'frear', 'freeman', 'freixo', 'frente', 'frota', 'frustram', 'frágil', 'fuga', 'fundador', 'fundo', 'furnas', 'fuzi', 'fábricas', 'fé', 'gaixa', 'galinhas', 'games', 'ganha', 'ganância', 'garantidos', 'gari', 'garoto', 'garrafão', 'garços', 'gaspari', 'gastar', 'gastas', 'gasto', 'gastos', 'gastou', 'gato', 'gera', 'geraria', 'gerir', 'gestão', 'gigantes', 'gilmar', 'golpe', 'google', 'gorjetas', 'governista', 'governo', 'govertno', 'govwerno', 'grave', 'grupos', 'grátis', 'guarda', 'guerra', 'guerras', 'guido', 'gutierrez', 'gás', 'haddad', 'hamilton', 'harmonia', 'hesitante', 'história', 'hoje', 'holanda', 'holandesa', 'homem', 'homologa', 'homologações', 'honorário', 'hospitais', 'hospital', 'hélio', 'idade', 'ideia', 'ideológico', 'idosos', 'iedi', 'ignora', 'ignoram', 'ilegais', 'ilícito', 'imaginário', 'imigrantes', 'imigração', 'impacto', 'impasse', 'impede', 'importações', 'imposto', 'impostos', 'imprensa', 'impulso', 'imóveis', 'inadimplentes', 'inativas', 'inativo', 'incerteza', 'inclui', 'incomum', 'incêndio', 'indca', 'indecisos', 'indefinidos', 'indenização', 'indica', 'indicam', 'indicia', 'indisciplina', 'indígenas', 'indústria', 'inferno', 'infiltrado', 'inflação', 'influencia', 'influência', 'infância', 'ingênuo', 'inimigo', 'injetar', 'inovação', 'inquérito', 'inquéritos', 'insegurança', 'instituto', 'instrumento', 'inteligência', 'intensa', 'interferir', 'interior', 'interpela', 'interrompe', 'intervenção', 'investidor', 'investiga', 'investigado', 'investigadores', 'investigados', 'investigará', 'investigativo', 'investigação', 'investigações', 'investimentos', 'investir', 'inédito', 'início', 'iptu', 'ir', 'irmã', 'irmão', 'irã', 'isabela', 'isenção', 'isolados', 'isso', 'istambul', 'itaipu', 'itaú', 'jacob', 'james', 'janor', 'janot', 'jato', 'jbs', 'joaquim', 'joesley', 'joga', 'jogador', 'joias', 'joio', 'jong', 'jornal', 'jornalismo', 'jornalista', 'jovens', 'jucá', 'juiz', 'julga', 'julgamento', 'julgar', 'juro', 'juros', 'jurídica', 'justiça', 'juízes', 'já', 'kassab', 'kim', 'lado', 'lamia', 'laranja', 'latam', 'latina', 'lauder', 'lava', 'lavanderia', 'legalizam', 'legalizar', 'legalização', 'legislativo', 'lei', 'leilão', 'leite', 'lemos', 'leniência', 'lentes', 'letras', 'leva', 'levado', 'levará', 'leve', 'libera', 'liberdade', 'liberta', 'licença', 'lidera', 'ligações', 'light', 'limita', 'limite', 'linha', 'lista', 'litoral', 'livros', 'lobão', 'lojas', 'londres', 'longe', 'longevidade', 'longo', 'lucra', 'lucro', 'lugar', 'luiz', 'lula', 'luta', 'luxo', 'líder', 'lúcia', 'maconha', 'macri', 'macron', 'maduro', 'mai', 'maia', 'maio', 'maior', 'maioria', 'maioridade', 'mais', 'mandato', 'mangueira', 'manobra', 'manoel', 'mantega', 'manter', 'manteve', 'mantiveram', 'mantém', 'mapa', 'mapeia', 'maranhão', 'marca', 'marcelo', 'marco', 'marina', 'marketing', 'marmitas', 'mas', 'massa', 'massacre', 'mata', 'matemática', 'matou', 'mauro', 'mcdermott', 'mediar', 'medicamento', 'medidas', 'medo', 'meio', 'melhorar', 'melhores', 'mello', 'menor', 'menos', 'mercado', 'mercados', 'mercosul', 'mercê', 'merendeira', 'meses', 'mesmo', 'mesquita', 'meta', 'metrô', 'mi', 'milhão', 'milhões', 'militar', 'minas', 'mineração', 'minha', 'ministro', 'ministros', 'ministério', 'mira', 'miram', 'missão', 'moderniza', 'monetária', 'monitores', 'moody', 'mora', 'moraes', 'morais', 'moreira', 'morgan', 'moro', 'morre', 'morrissey', 'morte', 'mortes', 'morto', 'mortos', 'mostra', 'mostram', 'mp', 'mpf', 'mps', 'muda', 'mudanças', 'mulher', 'multa', 'multar', 'multas', 'mundo', 'municipal', 'municípios', 'mãe', 'mão', 'mãos', 'média', 'mês', 'mínima', 'míriam', 'mônica', 'na', 'nacional', 'nas', 'nascimento', 'natural', 'nbsp', 'nega', 'negados', 'negocia', 'negócio', 'nelson', 'nem', 'nenhum', 'neto', 'netto', 'neve', 'ninguém', 'no', 'nome', 'nomear', 'nomes', 'norberto', 'normal', 'norte', 'nos', 'nota', 'notícia', 'notícias', 'nova', 'novatos', 'novela', 'novo', 'novos', 'nuclear', 'nunca', 'ny', 'não', 'nível', 'números', 'oab', 'obituário', 'obrigatória', 'obter', 'obtém', 'odebrecht', 'ofensiva', 'oferece', 'oferta', 'oficial', 'oi', 'omitiu', 'oms', 'onu', 'operador', 'operação', 'oposição', 'ordena', 'origens', 'os', 'otan', 'otimismo', 'outra', 'outras', 'ouvido', 'ovos', 'pacote', 'padilha', 'padre', 'padrinhos', 'paga', 'pagar', 'pago', 'pagou', 'palocci', 'panelaços', 'papel', 'para', 'paraguai', 'parar', 'parcelado', 'parente', 'partido', 'partidos', 'partir', 'pasquale', 'passa', 'passado', 'passapusso', 'passeava', 'pastor', 'paternidade', 'patrocínio', 'paulino', 'paulista', 'paulo', 'país', 'países', 'pcc', 'pede', 'pedem', 'pedido', 'pedir', 'pedro', 'pega', 'peito', 'pela', 'pelo', 'pena', 'penas', 'pensa', 'pensar', 'perda', 'perde', 'perder', 'perdi', 'permitido', 'permuta', 'personagem', 'pesada', 'pesquisa', 'pessimismo', 'pessimistas', 'pessoal', 'pessoas', 'petrobras', 'pezão', 'peças', 'pf', 'pgr', 'philips', 'pib', 'pichadores', 'pilares', 'piloto', 'pinguela', 'piora', 'pioram', 'pires', 'planalto', 'planejam', 'planetário', 'plano', 'plebiscito', 'plenário', 'pm', 'pmdb', 'pobre', 'pobres', 'pode', 'podem', 'poder', 'poderes', 'poderá', 'polarização', 'polêmica', 'polícia', 'política', 'políticas', 'político', 'políticos', 'pondé', 'população', 'por', 'porta', 'porto', 'posse', 'posses', 'pouco', 'poupa', 'povoa', 'prazo', 'precisa', 'preciso', 'precoce', 'precária', 'prefeitos', 'prefeitura', 'prega', 'premia', 'prender', 'preparam', 'presa', 'presidente', 'preso', 'presos', 'pressiona', 'pressionam', 'pressão', 'pretendem', 'preveem', 'previdenciária', 'previdência', 'prevê', 'primavera', 'primeira', 'prioriza', 'prisão', 'prisões', 'privacidade', 'privado', 'privatiza', 'privatizar', 'privatizações', 'privilegia', 'privilegiado', 'privilegiam', 'privilégio', 'processo', 'procuradores', 'produzir', 'programação', 'projeta', 'projeções', 'prolongada', 'promessa', 'promete', 'prontos', 'propina', 'proposta', 'propostas', 'proprietário', 'propõe', 'protecionismo', 'protestar', 'protesto', 'protestos', 'proteção', 'provoca', 'provocam', 'pré', 'prêmio', 'prêmios', 'psdb', 'psiquiátrico', 'pt', 'pune', 'punir', 'pureri', 'puxadinho', 'páreo', 'pão', 'põe', 'públicos', 'qual', 'quando', 'quase', 'quatro', 'que', 'quebra', 'queda', 'quem', 'quer', 'querem', 'questionou', 'radicais', 'ratifica', 'reagem', 'reagirá', 'real', 'reale', 'reação', 'rebelada', 'receberá', 'recebia', 'receita', 'recessão', 'recompra', 'recorde', 'recuará', 'recupera', 'recursos', 'recusa', 'rede', 'reduz', 'reduzir', 'reeditam', 'reeleição', 'referendo', 'refis', 'reforma', 'reformas', 'reforça', 'reforçar', 'reféns', 'regime', 'regra', 'regras', 'rejeita', 'relator', 'relatoria', 'remédio', 'renan', 'renascimento', 'renda', 'renegociação', 'rentabilidade', 'renunciar', 'repasse', 'repatriação', 'repatriou', 'repressão', 'repudiam', 'reputation', 'reputação', 'repõe', 'resiste', 'resistir', 'resistência', 'restringe', 'retalia', 'retoma', 'retomada', 'retomar', 'retorna', 'retração', 'revelações', 'reversíveis', 'revista', 'revisão', 'revés', 'rezo', 'richthofen', 'rico', 'rigor', 'rio', 'risco', 'ritmo', 'rivais', 'rolling', 'rolls', 'rombo', 'romper', 'ronaldo', 'rotativo', 'rotina', 'royalties', 'royce', 'ruas', 'rural', 'ruralistas', 'russas', 'russo', 'ruy', 'ré', 'réu', 'réveillon', 'rússia', 'sabe', 'saber', 'sacar', 'safra', 'sal', 'salvar', 'salário', 'samba', 'sapucaí', 'saque', 'saída', 'saúde', 'schwartsman', 'se', 'secretária', 'seguido', 'segundo', 'segurança', 'seis', 'seja', 'seletiva', 'selic', 'sem', 'semana', 'semestre', 'senado', 'senador', 'senadores', 'sentença', 'separação', 'separe', 'sequência', 'ser', 'serra', 'servidor', 'servidores', 'serviço', 'será', 'serãoouvidos', 'setores', 'seu', 'seul', 'shell', 'show', 'shwartsman', 'sido', 'sigilo', 'sinaliza', 'sindical', 'sindicato', 'sindicatos', 'sistema', 'sistêmica', 'sob', 'sobe', 'sobem', 'sobre', 'sobreviver', 'socar', 'sociedade', 'sofre', 'sortear', 'sorteio', 'souza', 'sp', 'startups', 'stf', 'stone', 'suas', 'subir', 'sucessão', 'suicida', 'sujo', 'sumiu', 'supera', 'superam', 'superpoder', 'supervia', 'suprema', 'supremo', 'surge', 'surpreende', 'suspeita', 'suspeitos', 'swift', 'são', 'sérgio', 'séries', 'sétimo', 'síria', 'sítio', 'só', 'sócio', 'takeda', 'tarefa', 'tarifa', 'tatuapé', 'taylor', 'teatro', 'tecnologia', 'teles', 'tem', 'teme', 'temem', 'temer', 'temor', 'tempestade', 'tempo', 'tempos', 'tensão', 'tenta', 'tentam', 'ter', 'terá', 'terão', 'teto', 'teve', 'ti', 'tinha', 'tio', 'tira', 'tirarei', 'tire', 'tiros', 'tiroteio', 'tiveram', 'tjlp', 'tlp', 'toda', 'todo', 'todos', 'tolerância', 'tomam', 'torcida', 'torino', 'torna', 'torre', 'torturar', 'toshiba', 'total', 'trabalhador', 'trabalhadores', 'trabalhista', 'trabalho', 'traficantes', 'tragédia', 'traições', 'transmissoras', 'transportes', 'tratamento', 'tratar', 'traz', 'trazem', 'tribunal', 'trigo', 'trimestre', 'troca', 'trocado', 'trump', 'tráfego', 'tráfico', 'três', 'tse', 'tst', 'tubarões', 'tucano', 'tucanos', 'tudo', 'turma', 'turquia', 'têm', 'título', 'ua', 'uber', 'ue', 'um', 'uma', 'umaq', 'un', 'unem', 'universal', 'universitários', 'união', 'urnas', 'us', 'usa', 'usado', 'usará', 'usava', 'uso', 'vacinado', 'vai', 'valem', 'valet', 'valor', 'varejo', 'vase', 'vazamento', 'veem', 'velloso', 'vence', 'venda', 'vendas', 'venezuela', 'ver', 'vermelha', 'versão', 'verticalizar', 'veto', 'vez', 'vezes', 'veículos', 'viajam', 'viajavam', 'vice', 'vida', 'vigor', 'vila', 'vinho', 'violência', 'vir', 'vira', 'virada', 'virou', 'visto', 'vitória', 'viver', 'vivo', 'vizinho', 'volta', 'voltar', 'von', 'voos', 'votar', 'votação', 'voto', 'votos', 'vão', 'vê', 'vício', 'vídeo', 'vítima', 'vítimas', 'xp', 'zaher', 'zeladoria', 'zelotes', 'zera', 'zero', 'zika', 'às', 'água', 'álbum', 'área', 'áudio', 'êxodo', 'índio', 'índios', 'óculos', 'órgãos', 'ônibus', 'ônus']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500000000) \n",
    "features = vectorizer.fit_transform(bowDb.CleanHeadline)\n",
    "features = features.toarray()\n",
    "print (features.shape)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print (vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos um vocabulário com 1633 palavras distintas.\n",
    "<br>Agora podemos ver quão representado no léxico esse vocabulário está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference: from https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "def count_word_occurences(features, vocabulary):\n",
    "    dist = np.sum(features, axis=0)\n",
    "    result = []\n",
    "    for tag, count in zip(vocabulary, dist):\n",
    "        result.append([count,tag])\n",
    "    result.sort(reverse=True)\n",
    "    return result\n",
    "\n",
    "#print (count_word_occurences(features, vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de palavras do vocabulário no corpus:6.307409675443969%\n"
     ]
    }
   ],
   "source": [
    "findings = 0\n",
    "for word in vocabulary:\n",
    "    correspWord = sentiLex[sentiLex.Word == word]\n",
    "    if not correspWord.empty:\n",
    "        findings += 1\n",
    "print (\"% de palavras do vocabulário no corpus:{}%\".format((findings / len(vocabulary))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos apenas 6.3% do vocabulário está contido no corpus sentiLex, é inviável utilizar o mesmo em nossa análise. Para contornar esse problema, poderíamos experimentar buscar no corpus _MacMorphos_ sinônimos/hiperônimos das palavras desconhecidas.\n",
    "\n",
    "Ainda poderíamos considerar outro corpus em português, porém devido à escassez dos mesmos, optamos por traduzir as manchetes pra o inglês e buscar os resultados no corpus _SentiWordNet_, que é muito mais extenso.\n",
    "\n",
    "Vale ressaltar que o corpus _SentiWordNet_ apresenta um aspecto interessante por não ter sido criado a partir de um único tipo de mídia, como avaliações de filmes ou produtos, mas sim a partir da avaliação sistemática de um outro corpus: o _wordnet_.\n",
    "\n",
    "Para tanto, iniciamos removendo os numerais das manchetes com o intuito de eliminar elementos irrelevantes.\n",
    "\n",
    "A documentação do _SentiWordNet_ está em: http://nmis.isti.cnr.it/sebastiani/Publications/LREC06.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordLines = []\n",
    "for line in translatedDb.Headline:\n",
    "    wordLines.append(re.sub(\"[0-9]\",\" \", line))\n",
    "    \n",
    "translatedDb.CleanHeadline = wordLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em sequência, para confirmarmos que o vocabulário em inglês é melhor representado no _SentiWordNet_, podemos montá-lo novamente e fazer a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de palavras do vocabulário no SentiWordNet:83.71%\n"
     ]
    }
   ],
   "source": [
    "def get_vocabulary(text):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 max_features = 500000000) \n",
    "#Huge max_features, we don't want to limit ourserves\n",
    "\n",
    "    features = vectorizer.fit_transform(text)\n",
    "    features = features.toarray()\n",
    "    #print (features.shape)\n",
    "    voc = vectorizer.get_feature_names()\n",
    "    return voc, features\n",
    "enVoc = get_vocabulary(translatedDb.CleanHeadline)[0]\n",
    "\n",
    "#print (enVoc)\n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "count = 0\n",
    "for word in enVoc:\n",
    "    sentiList = list(swn.senti_synsets(word))\n",
    "    if (len(sentiList) > 0):\n",
    "        count += 1\n",
    "print (\"% de palavras do vocabulário no SentiWordNet:{0:.2f}%\".format((count / len(enVoc))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora obtemos um resultado muito superior: 83.71% das palavras utilizadas estão contidas no corpus.\n",
    "<br>Antes de classificar as palavras, podemos remover novamente as _stopwords_, desta vez considerando o conjunto para o inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordLines = []\n",
    "\n",
    "for line in translatedDb.CleanHeadline:\n",
    "    words = ''\n",
    "    for word in line.split():\n",
    "        if word not in stopwords.words(\"english\"):\n",
    "            words = words + word + ' '\n",
    "    wordLines.append(words)\n",
    "\n",
    "translatedDb['CleanEnHeadline'] = wordLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essas informações, podemos obter a pontuação das palavras encontradas no corpus e calcular a média para cada sentença. \n",
    "<br>Uma observação relevante é que motivo de usarmos um _threshold_, uma margem de ativação em termos, é para criar um limiar mais brando de resultados medianos, e impedir que frases classificadas com leves valências positivas ou negativas estejam juntas com frases de valências fortes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>BlobSentimentsP</th>\n",
       "      <th>BlobSentimentsNB</th>\n",
       "      <th>CleanEnHeadline</th>\n",
       "      <th>SW_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES shrinks back to the level of 20 years ago'</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.879188...</td>\n",
       "      <td>'BNDES shrinks back level years ago'</td>\n",
       "      <td>[0.0, 0.0625, neg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC creates new monetary policy instrument.'</td>\n",
       "      <td>Sentiment(polarity=0.13636363636363635, subjec...</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.989948...</td>\n",
       "      <td>'BC creates new monetary policy instrument.'</td>\n",
       "      <td>[0.046875, 0.03125, pos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Exchange generates word of mouth between AU a...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.650384...</td>\n",
       "      <td>'Exchange generates word mouth AU EU.'</td>\n",
       "      <td>[0.028846153846153848, 0.028846153846153848, mid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indemnification to energy transmitters has al...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.575931...</td>\n",
       "      <td>'Indemnification energy transmitters already r...</td>\n",
       "      <td>[0.027777777777777776, 0.020833333333333332, pos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>\"Politicians expect rapporteur to separate\" wh...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.933297...</td>\n",
       "      <td>\"Politicians expect rapporteur separate\" wheat...</td>\n",
       "      <td>[0.03409090909090909, 0.028409090909090908, pos]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Day        Month  Year   Source  \\\n",
       "0             0    1  'fevereiro'  2017  'Valor'   \n",
       "1             1    1  'fevereiro'  2017  'Valor'   \n",
       "2             2    1  'fevereiro'  2017  'Valor'   \n",
       "3             3    1  'fevereiro'  2017  'Valor'   \n",
       "4             4    1  'fevereiro'  2017  'Valor'   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  'BNDES shrinks back to the level of 20 years ago'   \n",
       "1       'BC creates new monetary policy instrument.'   \n",
       "2  'Exchange generates word of mouth between AU a...   \n",
       "3  'Indemnification to energy transmitters has al...   \n",
       "4  \"Politicians expect rapporteur to separate\" wh...   \n",
       "\n",
       "                                     BlobSentimentsP  \\\n",
       "0          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "1  Sentiment(polarity=0.13636363636363635, subjec...   \n",
       "2          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "3          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "4          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "\n",
       "                                    BlobSentimentsNB  \\\n",
       "0  Sentiment(classification='pos', p_pos=0.879188...   \n",
       "1  Sentiment(classification='pos', p_pos=0.989948...   \n",
       "2  Sentiment(classification='pos', p_pos=0.650384...   \n",
       "3  Sentiment(classification='pos', p_pos=0.575931...   \n",
       "4  Sentiment(classification='pos', p_pos=0.933297...   \n",
       "\n",
       "                                     CleanEnHeadline  \\\n",
       "0              'BNDES shrinks back level years ago'    \n",
       "1      'BC creates new monetary policy instrument.'    \n",
       "2            'Exchange generates word mouth AU EU.'    \n",
       "3  'Indemnification energy transmitters already r...   \n",
       "4  \"Politicians expect rapporteur separate\" wheat...   \n",
       "\n",
       "                                            SW_Score  \n",
       "0                                 [0.0, 0.0625, neg]  \n",
       "1                           [0.046875, 0.03125, pos]  \n",
       "2  [0.028846153846153848, 0.028846153846153848, mid]  \n",
       "3  [0.027777777777777776, 0.020833333333333332, pos]  \n",
       "4   [0.03409090909090909, 0.028409090909090908, pos]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "wordScores = []\n",
    "posWordScores = []\n",
    "negWordScores = []\n",
    "lineScores = []\n",
    "lineScore = 0\n",
    "THRESHOLD = 0.005\n",
    "for line in translatedDb.CleanHeadline:\n",
    "    words = ''\n",
    "    wordScores = []\n",
    "    for word in line.split():\n",
    "        sentiList = list(swn.senti_synsets(word))\n",
    "        if len(sentiList) > 0:\n",
    "            \n",
    "            posWordScores.append(sentiList[0].pos_score())\n",
    "            negWordScores.append(sentiList[0].neg_score())\n",
    "            \n",
    "    if len(posWordScores) != 0: \n",
    "        posMean = mean(posWordScores)\n",
    "        negMean = mean(negWordScores)\n",
    "        if posMean > (negMean + THRESHOLD):\n",
    "            result = 'pos'\n",
    "        elif negMean > (posMean + THRESHOLD):\n",
    "            result = 'neg'\n",
    "        else:\n",
    "            result = 'mid'\n",
    "        lineScores.append([posMean, negMean, result ])\n",
    "    else:\n",
    "        lineScores.append([0,0])\n",
    "                          \n",
    "translatedDb['SW_Score'] = lineScores\n",
    "display(translatedDb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Com isso temos a classificação para cada uma das sentenças. Em um primeiro momento, é perceptível uma certa discrepância entre esse método e os outros dois apresentados anteriormente, como na manchete \"BNDES encolhe e volta ao nível de 20 anos atrás\", já que a última abordagem classificou a notícia como negativa, a pattern como neutra e a Naive Bayes como positiva.\n",
    "<br>Este comportamento pode estar relacionado com a forma com que o banco de palavras do SentiWordNet foi montado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader\n",
    "\n",
    "O analisador de texto Vader tem como base um vocabulário tipicamente usado em conversas informais, e é limitado à análise de frases únicas, sentenças isoladas. O banco de treinamento do Vader é treinado para compreender intensificadores de sentimentos (boosters), e utiliza bancos existentes em conjunto com muitas novas palavras e avaliações realizadas por humanos.\n",
    "<br>Ele foi inicialmente imaginado como um analisador de mensagens de texto (sms) e frases em redes sociais, como o Twitter. A criação minuciosa de um novo banco de dados contendo gírias (slang) e emoticons permite uma análise mais correta desse tipo de mídia escrita informal, e consequentemente cria um bom ambiente de testes para manchetes curtas de jornal.\n",
    "\n",
    "A documentação toda do analisador de sentimentos Vader está disponível em: https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>BlobSentimentsP</th>\n",
       "      <th>BlobSentimentsNB</th>\n",
       "      <th>CleanEnHeadline</th>\n",
       "      <th>SW_Score</th>\n",
       "      <th>Vader_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BNDES shrinks back to the level of 20 years ago'</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.879188...</td>\n",
       "      <td>'BNDES shrinks back level years ago'</td>\n",
       "      <td>[0.0, 0.0625, neg]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'BC creates new monetary policy instrument.'</td>\n",
       "      <td>Sentiment(polarity=0.13636363636363635, subjec...</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.989948...</td>\n",
       "      <td>'BC creates new monetary policy instrument.'</td>\n",
       "      <td>[0.046875, 0.03125, pos]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Exchange generates word of mouth between AU a...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.650384...</td>\n",
       "      <td>'Exchange generates word mouth AU EU.'</td>\n",
       "      <td>[0.028846153846153848, 0.028846153846153848, mid]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>'Indemnification to energy transmitters has al...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.575931...</td>\n",
       "      <td>'Indemnification energy transmitters already r...</td>\n",
       "      <td>[0.027777777777777776, 0.020833333333333332, pos]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.533, 'pos': 0.467, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>'fevereiro'</td>\n",
       "      <td>2017</td>\n",
       "      <td>'Valor'</td>\n",
       "      <td>\"Politicians expect rapporteur to separate\" wh...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>Sentiment(classification='pos', p_pos=0.933297...</td>\n",
       "      <td>\"Politicians expect rapporteur separate\" wheat...</td>\n",
       "      <td>[0.03409090909090909, 0.028409090909090908, pos]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Day        Month  Year   Source  \\\n",
       "0             0    1  'fevereiro'  2017  'Valor'   \n",
       "1             1    1  'fevereiro'  2017  'Valor'   \n",
       "2             2    1  'fevereiro'  2017  'Valor'   \n",
       "3             3    1  'fevereiro'  2017  'Valor'   \n",
       "4             4    1  'fevereiro'  2017  'Valor'   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  'BNDES shrinks back to the level of 20 years ago'   \n",
       "1       'BC creates new monetary policy instrument.'   \n",
       "2  'Exchange generates word of mouth between AU a...   \n",
       "3  'Indemnification to energy transmitters has al...   \n",
       "4  \"Politicians expect rapporteur to separate\" wh...   \n",
       "\n",
       "                                     BlobSentimentsP  \\\n",
       "0          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "1  Sentiment(polarity=0.13636363636363635, subjec...   \n",
       "2          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "3          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "4          Sentiment(polarity=0.0, subjectivity=0.0)   \n",
       "\n",
       "                                    BlobSentimentsNB  \\\n",
       "0  Sentiment(classification='pos', p_pos=0.879188...   \n",
       "1  Sentiment(classification='pos', p_pos=0.989948...   \n",
       "2  Sentiment(classification='pos', p_pos=0.650384...   \n",
       "3  Sentiment(classification='pos', p_pos=0.575931...   \n",
       "4  Sentiment(classification='pos', p_pos=0.933297...   \n",
       "\n",
       "                                     CleanEnHeadline  \\\n",
       "0              'BNDES shrinks back level years ago'    \n",
       "1      'BC creates new monetary policy instrument.'    \n",
       "2            'Exchange generates word mouth AU EU.'    \n",
       "3  'Indemnification energy transmitters already r...   \n",
       "4  \"Politicians expect rapporteur separate\" wheat...   \n",
       "\n",
       "                                            SW_Score  \\\n",
       "0                                 [0.0, 0.0625, neg]   \n",
       "1                           [0.046875, 0.03125, pos]   \n",
       "2  [0.028846153846153848, 0.028846153846153848, mid]   \n",
       "3  [0.027777777777777776, 0.020833333333333332, pos]   \n",
       "4   [0.03409090909090909, 0.028409090909090908, pos]   \n",
       "\n",
       "                                         Vader_Score  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.0, 'neu': 0.533, 'pos': 0.467, 'comp...  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vaderSent = []\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "for line in translatedDb.CleanEnHeadline:\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(line)\n",
    "    vaderSent.append(ss)\n",
    "translatedDb['Vader_Score'] = vaderSent\n",
    "display(translatedDb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma análise preliminar, o Vader demonstra resultados superiores às outras implementações, embora uma análise detalhada é feita na seção de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translatedDb.to_csv('translatedDbScored.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "A fim de realizar uma análise comparativa de eficácia, selecionamos algumas manchetes e como esperávamos que elas iriam se comportar:\n",
    "## Manchetes negativas\n",
    "\n",
    "Escolhemos cinco manchetes com conotações negativas, para as quais esperávamos obter uma valência correspondentemente negativa, e analisamos os resultados de acordo com o esperado de cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Elio Gaspari: Presidente bate recorde em perda de colaboradores.'\n",
      "'Elio Gaspari: President sets record in loss of employees.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.7905550485897339, p_neg=0.2094449514102658)\n",
      "\n",
      "SentiWord: \n",
      "[0.04121621621621622, 0.04054054054054054, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.277, 'neu': 0.723, 'pos': 0.0, 'compound': -0.3182}\n"
     ]
    }
   ],
   "source": [
    "n=43\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matéria é claramente negativa, especialmente ao analisar o bigrama \"record loss\", ou o trigrama \"record loss employees\", mas \"record\" sozinha pode ser avaliada como positiva incorretamente.\n",
    "\n",
    "Vemos que o TextBlob Pattern não conseguiu analisar nenhuma das palavras chave da manchete, provavelmente não contendo nenhuma das palavras em seu corpus. O TextBlob Naive Bayes avaliou a matéria como positiva, provavelmente ao analisar a palavra \"record\", que possui valência positiva maior do que a valência negativa de \"loss\". O SentiWord classificou a matéria como 'mid'. Já o Vader conseguiu pegar a nuância negativa, e apesar de ter um valor neutro alto, conseguiu deixar o compound em negativo.\n",
    "Nesta manchete, percebemos que a utilização de valências palavra-a-palavra (unigramas) compromete certas construções de frases, especialmente quando há a presença de palavras intensificadoras que têm certa valência quando analisadas individualmente.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Atentado mata 90 pessoas em Cabul.'\n",
      "'Attack kills 90 people in Kabul.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.4344497687542783, p_neg=0.5655502312457213)\n",
      "\n",
      "SentiWord: \n",
      "[0.03596866096866097, 0.032407407407407406, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.767, 'neu': 0.233, 'pos': 0.0, 'compound': -0.765}\n"
     ]
    }
   ],
   "source": [
    "n=82\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchete indica morte de 90 pessoas em Kabul, e a palavra \"attack\" pode ser mal-interpretada usando o banco de dados de análises de filmes.\n",
    "Esta manchete também não é analisada corretamente pelo TextBlob Pattern, que a indica como puramente neutra. Já o TextBlob Naive Bayes classificou a manchete como negativa, embora tenha sido por uma margem pequena. O SentiWord analisou a matéria como positiva. Cremos que essas tendências ao positivo inclua a palavra \"ataque\", que sem contexto não pode ser atribuída a terrorismos ou atentados, e o lado negativo seja graças à palavra \"kills\". O Vader conseguiu avaliar a matéria como altamente negativa, dando um score composto bastante negativo. De um ponto de vista básico, o Vader foi o mais preciso, ao atribuir um score negativo alto e um composto devidamente negativo.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Homem mata a tiros ex-mulher filho e mais dez.'\n",
      "'Man kills the ex-wife son and ten more.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.25, subjectivity=0.25)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.3817142012032676, p_neg=0.6182857987967325)\n",
      "\n",
      "SentiWord: \n",
      "[0.03704588910133843, 0.04206500956022945, 'neg']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.412, 'neu': 0.588, 'pos': 0.0, 'compound': -0.5423}\n"
     ]
    }
   ],
   "source": [
    "n=125\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O uso da palavra \"kills\" deveria indicar a valência negativa, mas o contexto de nomear \"son\", \"ex-wife\", \"more\" pode confundir o processamento.\n",
    "Nesta manchete, ambos o TextBlob Naive Bayes e o SentiWord conseguiram classificar a matéria como negativa, enquanto o TextBlob Pattern colocou a valência em 0.25, o que corresponderia a uma valência positiva. Possivelmente o uso da palavra \"more\" puxou a valência para o positivo, e \"kills\" para o negativo. A análise do Vader conseguiu mais uma vez classificar corretamente como negativo, com um score final de -0.5, que indicaria uma manchete bastante negativa.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ataque suicida matou 80 crianças.'\n",
      "'Suicide attack killed 80 children.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=-0.2, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.4280023076587344, p_neg=0.5719976923412652)\n",
      "\n",
      "SentiWord: \n",
      "[0.038643533123028394, 0.04305993690851735, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.924, 'neu': 0.076, 'pos': 0.0, 'compound': -0.9201}\n"
     ]
    }
   ],
   "source": [
    "n=406\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchete negativa especialmente pelo uso das palavras \"suicide\", \"attack\", \"killed\". \"Children\" pode confundir o processamento, bem como \"attack\" pode ser mal-interpretado sem o contexto apropriado.\n",
    "A manchete que possuía a palavra-chave \"suicídio\" foi classificada negativa pelo TextBlob Pattern e pelo TextBlob Naive Bayes, mas teve classificação \"mid\" pelo SentiWord, possivelmente tendo sido combatida pela valência positiva de \"crianças\" avaliada independentemente. Ter usado algo maior do que unigramas aqui teria feito diferença em identificar o contexto das crianças. Pelo Vader, temos um dos maiores scores negativos, com um score final de -0.92, que está próximo do mais negativo possível (-1.00).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ataque a mesquita no Canadá deixa ao menos seis mortos.'\n",
      "'Attack on mosque in Canada leaves at least six dead.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=-0.25, subjectivity=0.4)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.3698658755476561, p_neg=0.6301341244523436)\n",
      "\n",
      "SentiWord: \n",
      "[0.03976272066458982, 0.04227258566978193, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.341, 'neu': 0.659, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "n=485\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras-chave são \"attack\", que pode acabar tendo valências diferentes dependendo do contexto, e \"kills\", que é geralmente negativa.\n",
    "Caso similar ao anterior, TextBlob Pattern e TextBlob Naive Bayes classificaram corretamente a manchete como negativa, bem como o Vader, mas o SentiWord ficou em \"mid\", com um score negativo levemente mais alto que o positivo. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manchetes positivas\n",
    "\n",
    "Notamos dificuldade em encontrar manchetes com conotação positiva, então optamos por selecionar aquelas que tinham palavras específicas que poderiam ser consideradas positivas, tentando prever o comportamento do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Doria atribui doações a altruísmo empresarial.'\n",
      "'Doria attributes donations to corporate altruism.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.3181818181818187, p_neg=0.681818181818181)\n",
      "\n",
      "SentiWord: \n",
      "[0.037162162162162164, 0.03885135135135135, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "n=32\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manchete deve ser avaliada como positiva dadas as palavras-chave \"altruism\", \"donations\", mas vemos que alguns algoritmos não conseguem identificar essas nuâncias. O TextBlob Naive Bayes classificou incorretamente como negativa, o SentiWord como mid, e o Vader e o TextBlob Pattern não conseguiram sair de um resultado de total neutralidade.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Com FGTS varejo volta a crescer.'\n",
      "'With FGTS retail grow back.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.49989808397880164, p_neg=0.5001019160211981)\n",
      "\n",
      "SentiWord: \n",
      "[0.037435233160621764, 0.04015544041450777, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "n=242\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manchete em português era positiva, anunciando o crescimento do varejo graças ao FGTS, mas em inglês essa nuância é perdida, embora ainda contenha \"grow back\" como palavras-chave, que deveriam puxar para o positivo. Todos estão quase que perfeitamente no neutro, e a classificação do TextBlob Naive Bayes é graças a uma diferença de 0.0001 a mais no score negativo.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Relator quer MP do Refis mais favorável a empresas.'\n",
      "'Rapporteur wants MP of Refis more favorable to companies.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.35, subjectivity=0.3)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.8157045314347129, p_neg=0.18429546856528692)\n",
      "\n",
      "SentiWord: \n",
      "[0.0384521484375, 0.03955078125, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 0.617, 'pos': 0.383, 'compound': 0.4767}\n"
     ]
    }
   ],
   "source": [
    "n=257\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchete que contém palavras \"favorable\", \"wants\", que deveria puxar para o positivo considerando as palavras independentemente.\n",
    "Vemos que o TextBlob Pattern conseguiu identificar algumas palavras e classificar a manchete como positiva, bem como o TextBlob Naive Bayes, que colocou a manchete em um score bem alto positivo. A análise do Vader classificou a manchete como bastante positiva, e o SentiWord a colocou no mid.\n",
    "De uma maneira geral, as palavras nesta manchete conseguiram ser identificadas mais facilmente pelos algoritmos.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'XP quer ser líder em cinco anos.'\n",
      "'XP wants to be a leader in five years.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.2, subjectivity=0.1)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.6447161967612489, p_neg=0.3552838032387515)\n",
      "\n",
      "SentiWord: \n",
      "[0.03872462488967343, 0.040158870255957636, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.516}\n"
     ]
    }
   ],
   "source": [
    "n=283\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo deve identificar as palavras \"wants\", \"leader\", embora a manchete não seja total e empiricamente boa. Vemos esse resultado em todos os métodos exceto o SentiWord, que classifica a manchete como levemente mais negativa.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Casos de suspeita de dengue e zika caem em média 90% no ano.'\n",
      "'Cases of suspected dengue fever and zika fall on average 90% in the year.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=-0.15, subjectivity=0.39999999999999997)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.6333116741900876, p_neg=0.36668832580991295)\n",
      "\n",
      "SentiWord: \n",
      "[0.038526752072343635, 0.04163526752072343, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.213, 'neu': 0.787, 'pos': 0.0, 'compound': -0.2263}\n"
     ]
    }
   ],
   "source": [
    "n=332\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchete na qual o contexto das palavras leva a uma notícia empiricamente boa, mas há uma dificuldade dos algoritmos de identificar isso como uma coisa boa. Palavras-chave \"fall\", \"fever\", \"suspected\", que podem levar para o negativo. O método de Naive Bayes conseguiu prever adequadamente a classificação positiva, enquanto os outros todos classificaram como mais negativo do que positivo.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manchetes escolhidas aleatoriamente\n",
    "\n",
    "Para estas cinco manchetes a seguir, utilizamos um algoritmo gerador de números aleatórios, eliminando quaisquer manchetes que já tivessem sido analisadas nos casos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Joesley deu dinheiro a firma da qual filho de Mantega foi sócio.'\n",
      "'Joesley gave money to the firm of which Mantega's son was a partner.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=-0.2, subjectivity=0.4)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.5122892109143866, p_neg=0.4877107890856142)\n",
      "\n",
      "SentiWord: \n",
      "[0.03482142857142857, 0.03616071428571429, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "n=66\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À primeira vista, não há nenhuma palavra-chave que funcione muito bem sem contexto aplicado. \"Gave\" pode ser um indicativo de positivo, bem como \"partner\". Vemos que o TextBlob Pattern analisa como negativo, mas com alto índice de subjetividade. O método de Naive Bayes analisa como positivo.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sérgio Cabral é condenado a 14 anos na Lava-Jato.'\n",
      "'Sérgio Cabral is sentenced to 14 years in the Lava-Jet.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.4861680150974352, p_neg=0.5138319849025648)\n",
      "\n",
      "SentiWord: \n",
      "[0.03765368852459016, 0.04008709016393443, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.216, 'neu': 0.784, 'pos': 0.0, 'compound': -0.0258}\n"
     ]
    }
   ],
   "source": [
    "n=247\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavra-chave \"sentenced\", e embora seja algo subjetivamente positivo, a palavra carrega uma conotação negativa quando avaliada independentemente.\n",
    "Fora o TextBlob Pattern, todos os algoritmos consideraram a manchete como mais negativa do que positiva. O Vader identificou apenas palavras negativas e neutras.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ex-presidente depõe e diz que é vítima de \"quase um massacre\".'\n",
      "'Former president testifies and says he is the victim of' almost a massacre '. \"\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=-0.037500000000000006, subjectivity=0.025)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='neg', p_pos=0.4330732470389665, p_neg=0.5669267529610326)\n",
      "\n",
      "SentiWord: \n",
      "[0.039116296863045144, 0.041507268553940324, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.208, 'neu': 0.792, 'pos': 0.0, 'compound': -0.2732}\n"
     ]
    }
   ],
   "source": [
    "n=329\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavra-chave forte \"massacre\", juntamente com \"victim\", o que deve levar a análise automática para uma análise que resulta em perceber uma conotação negativa aparente. Todos os algoritmos identificaram um sentimento negativo mais forte, graças às palavras acima.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Velloso pode comandar a Justiça.'\n",
      "'Velloso can command justice.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.8247275974319552, p_neg=0.17527240256804413)\n",
      "\n",
      "SentiWord: \n",
      "[0.038461538461538464, 0.041908563134978226, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "n=347\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manchete tem palavras positivas, como \"command\" e \"justice\", então é esperado que o algoritmo identifique a valência positiva da frase, mas vemos isso somente no TextBlob Naive Bayes. O TextBlob Pattern e o Vader não conseguiram sair do neutro, e o SentiWord identificou a manchete como mais negativa do que positiva.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Eike se entrega e indca que vai colaborar com investigações.'\n",
      "'Eike surrenders and indicates that he will collaborate with investigations.'\n",
      "\n",
      "TextBlob Pattern: \n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "TextBlob Naive Bayes: \n",
      "Sentiment(classification='pos', p_pos=0.975638392557124, p_neg=0.02436160744287506)\n",
      "\n",
      "SentiWord: \n",
      "[0.03994670846394984, 0.042537617554858936, 'mid']\n",
      "\n",
      "Vader: \n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "n=483\n",
    "print(originalDb.iloc[n].Headline)\n",
    "print(translatedDb.iloc[n].Headline)\n",
    "print('\\nTextBlob Pattern: \\n'+translatedDb.iloc[n].BlobSentimentsP)\n",
    "print('\\nTextBlob Naive Bayes: \\n'+translatedDb.iloc[n].BlobSentimentsNB+'\\n')\n",
    "print('SentiWord: ')\n",
    "print(translatedDb.SW_Score.iloc[n])\n",
    "print('\\nVader: ')\n",
    "print(translatedDb.Vader_Score.iloc[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras-chave positivas devem pesar mais do que as negativas, no caso \"surrenders\" carrega uma valência provavelmente positiva, bem como \"collaborate\", verbos de ação que indicam uma ação positiva. Vemos que o TextBlob Pattern e o Vader não saíram do neutro mais uma vez, mas o TextBlob Naive Bayes deu o maior score positivo já visto nos nossos resultados.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pontos Fracos e Fortes\n",
    "Após analisar cada uma das quinze manchetes escolhidas, podemos obter algumas conclusões a respeito dos quatro algoritmos que usamos.\n",
    "\n",
    "Vimos que a **TextBlob Pattern** é, em termos, a mais rudimentar delas. Capaz de avaliar a polaridade de -1.0 (mais negativa possível) a 1.0 (mais positiva possível), mas incapaz de determinar contextos como vimos em muitos dos resultados.\n",
    "<br>Cremos que isso possa acontecer devido ao fato do vocabulário de avaliações de produtos terem, normalmente, um léxico menor do que outros bancos de dados.\n",
    "\n",
    "O **TextBlob Naive Bayes** possui um resultado coerente na maioria das vezes, mas possui alguns \"falsos positivos\" ao utilizar um corpus de avaliações de filmes. Teorizamos que algumas das palavras usadas negativamente em manchetes podem ser usadas em avaliações boas de filmes, tal como já mencionado que \"medo\" e \"susto\" podem ser palavras usadas para ilustrar aspectos positivos de um filme de terror.\n",
    "<br>Podemos perceber esta influência do conjunto de treinamento de avaliações de filmes em manchetes como: \n",
    "\n",
    "_'Fear of more repression empties streets of Asunción.'_\n",
    "Sentiment(classification='**pos**', p_pos=0.904, p_neg=0.096)\n",
    "\n",
    "_'Young people study in fear.'_\n",
    "Sentiment(classification='**pos**', p_pos=0.82, p_neg=0.18)\n",
    "\n",
    "\n",
    "O **SentiWordNet** é um banco de palavras criado a partir de uma atribuição manual, e usa unigramas para a análise. Podemos ver esse resultado em várias das manchetes, nas quais algumas poucas palavras determinam incorretamente o resultado do sentimento da frase.\n",
    "\n",
    "Para frases curtas, o **Vader** apresenta resultados coerentes graças às suas atribuições de palavras intensificadoras e sua capacidade de analisar o contexto da frase toda. Um ponto fraco é seu pequeno dicionário de valências. Se ele fosse atualizado com mais algumas centenas de palavras, poderia melhorar bastante suas já ótimas análises.\n",
    "\n",
    "\n",
    "# Lições Aprendidas\n",
    "\n",
    "Pudemos perceber que analisar o contexto das frases é essencial, e a utilização de unigramas compromete de certa forma a análise como um todo. O uso de palavras intensificadoras (_boosters_) contribui bastante para um resultado coerente, embora ainda não estejamos no nível de captar certas nuâncias implícitas pelo contexto.\n",
    "\n",
    "\n",
    "# Trabalhos Futuros\n",
    "\n",
    "\n",
    "Futuramente, é possível implementar funções que determinem a valência de uma sentença a partir da avaliação de diversões classificadores distintos, unificando o resultado.\n",
    "<br>Vemos que, com uma base desta, é possível criar uma série de sistemas que usam os resultados de análises de sentimentos para comparar canais de comunicação em diversas vertentes. Podemos por exemplo avaliar se um site de notícias é muito negativo, ou ver se um dia em especial teve uma valência muito positiva para todos os jornais, dentre outras possibilidades.\n",
    "<br> Por fim, existe a possibilidade de futuramente implementar aspectos de automatização para este trabalho, como processar bancos de dados originais diretamente de arquivos CSV, tratar erros de digitação nestes bancos, e até mesmo obter novas manchetes diretamente de sites de notícias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bônus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises dos Jornais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos vocabulários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso primeiro passo é isolar as manchetes de cada jornal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos: \n",
      " 127 Manchetes da Folha \n",
      " 118 Manchetes do Valor \n",
      " 129 Manchetes do Estado\n",
      " 126 Manchetes do Globo\n"
     ]
    }
   ],
   "source": [
    "valor = originalDb[originalDb.Source=='\\'Valor\\'']\n",
    "folha = originalDb[originalDb.Source=='\\'Folha\\'']\n",
    "estado = originalDb[originalDb.Source == '\\'Estado\\'']\n",
    "globo = originalDb[originalDb.Source == '\\'Globo\\'']\n",
    "\n",
    "print ('Temos: \\n {0} Manchetes da Folha \\n {1} Manchetes do Valor \\n {2} Manchetes do Estado\\n {3} Manchetes do Globo'\n",
    "       .format(len(folha), len(valor), len(estado), len(globo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as manchetes isoladas, é possível montarmos o vocabulário específico de cada jornal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais usadas no Valor: \n",
      " [[40, 'de'], [20, 'da'], [16, 'para'], [16, 'do'], [9, 'no'], [7, 'novo'], [7, 'governo'], [7, 'em'], [6, 'temer'], [6, 'mais'], [5, 'trump'], [5, 'já'], [5, 'brasil'], [5, 'ao'], [4, 'vão'], [4, 'volta'], [4, 'se'], [4, 'que'], [4, 'por'], [4, 'pode']]\n",
      "Mais usadas na Folha: \n",
      " [[57, 'de'], [26, 'em'], [26, 'da'], [16, 'do'], [14, 'no'], [13, 'que'], [13, 'para'], [13, 'na'], [9, 'temer'], [9, 'diz'], [8, 'não'], [7, 'mais'], [7, 'com'], [6, 'um'], [6, 'sem'], [6, 'se'], [6, 'presidente'], [6, 'governo'], [6, 'doria'], [6, 'deve']]\n",
      "Mais usadas no Estado: \n",
      " [[51, 'de'], [21, 'do'], [18, 'em'], [14, 'da'], [11, 'na'], [10, 'para'], [10, 'no'], [9, 'com'], [8, 'trump'], [7, 'temer'], [7, 'que'], [7, 'diz'], [6, 'quer'], [5, 'sobre'], [5, 'mantém'], [5, 'dos'], [4, 'vai'], [4, 'stf'], [4, 'sp'], [4, 'por']]\n",
      "Mais usadas no Globo: \n",
      " [[42, 'de'], [19, 'da'], [16, 'do'], [12, 'na'], [12, 'em'], [10, 'para'], [10, 'no'], [9, 'temer'], [7, 'vai'], [6, 'trump'], [6, 'com'], [6, 'ao'], [5, 'tem'], [5, 'já'], [5, 'as'], [4, 'rio'], [4, 'pode'], [4, 'não'], [4, 'lava'], [4, 'dos']]\n"
     ]
    }
   ],
   "source": [
    "valorVoc, valorFeat = get_vocabulary(valor.Headline)\n",
    "folhaVoc, folhaFeat = get_vocabulary(folha.Headline)\n",
    "estadoVoc, estadoFeat = get_vocabulary(estado.Headline)\n",
    "globoVoc, globoFeat = get_vocabulary(globo.Headline)\n",
    "def show_most_used_words(vocabulary, features):\n",
    "    return (count_word_occurences(features, vocabulary)[:20])\n",
    "\n",
    "print(\"Mais usadas no Valor: \\n {}\".format(show_most_used_words(valorVoc, valorFeat)))\n",
    "print(\"Mais usadas na Folha: \\n {}\".format(show_most_used_words(folhaVoc, folhaFeat)))\n",
    "print(\"Mais usadas no Estado: \\n {}\".format(show_most_used_words(estadoVoc, estadoFeat)))\n",
    "print(\"Mais usadas no Globo: \\n {}\".format(show_most_used_words(globoVoc, globoFeat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, as palavras mais recorrentes são em sua maioria _stopwords_.\n",
    "Para uma análise melhor, podemos removê-las e reavaliar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mais usadas no Valor: \n",
      " [[7, 'novo'], [7, 'governo'], [6, 'temer'], [5, 'trump'], [5, 'brasil'], [4, 'vão'], [4, 'volta'], [4, 'pode'], [4, 'eua'], [4, 'diz'], [4, 'bi'], [3, 'vê'], [3, 'us'], [3, 'ser'], [3, 'quer'], [3, 'política'], [3, 'país'], [3, 'odebrecht'], [3, 'mercado'], [3, 'indenização']]\n",
      "\n",
      "Mais usadas na Folha: \n",
      " [[9, 'temer'], [9, 'diz'], [6, 'presidente'], [6, 'governo'], [6, 'doria'], [6, 'deve'], [5, 'trump'], [5, 'ter'], [5, 'país'], [5, 'menos'], [5, 'crise'], [5, 'contra'], [5, 'brasil'], [4, 'stf'], [4, 'sp'], [4, 'sobre'], [4, 'odebrecht'], [4, 'nova'], [4, 'maduro'], [4, 'lula']]\n",
      "\n",
      "Mais usadas no Estado: \n",
      " [[8, 'trump'], [7, 'temer'], [7, 'diz'], [6, 'quer'], [5, 'sobre'], [5, 'mantém'], [4, 'vai'], [4, 'stf'], [4, 'sp'], [4, 'pede'], [4, 'governo'], [4, 'eua'], [4, 'brasil'], [4, 'anos'], [3, 'volta'], [3, 'vezes'], [3, 'total'], [3, 'supremo'], [3, 'supera'], [3, 'reforma']]\n",
      "\n",
      "Mais usadas no Globo: \n",
      " [[9, 'temer'], [7, 'vai'], [6, 'trump'], [4, 'rio'], [4, 'pode'], [4, 'lava'], [4, 'em'], [4, 'crivella'], [3, 'volta'], [3, 'stf'], [3, 'odebrecht'], [3, 'jato'], [3, 'ir'], [3, 'fundo'], [3, 'fgts'], [3, 'deve'], [3, 'contra'], [3, 'bi'], [3, 'aécio'], [3, 'apoio']]\n"
     ]
    }
   ],
   "source": [
    "bowDb.CleanHeadline\n",
    "valor = bowDb[bowDb.Source=='\\'Valor\\'']\n",
    "valorVoc, valorFeat = get_vocabulary(valor.CleanHeadline)\n",
    "folha = bowDb[bowDb.Source=='\\'Folha\\'']\n",
    "folhaVoc, folhaFeat = get_vocabulary(folha.CleanHeadline)\n",
    "estado = bowDb[bowDb.Source == '\\'Estado\\'']\n",
    "estadoVoc, estadoFeat = get_vocabulary(estado.CleanHeadline)\n",
    "globo = bowDb[bowDb.Source == '\\'Globo\\'']\n",
    "globoVoc, globoFeat = get_vocabulary(globo.CleanHeadline)\n",
    "print(\"\\nMais usadas no Valor: \\n {}\".format(show_most_used_words(valorVoc, valorFeat)))\n",
    "print(\"\\nMais usadas na Folha: \\n {}\".format(show_most_used_words(folhaVoc, folhaFeat)))\n",
    "print(\"\\nMais usadas no Estado: \\n {}\".format(show_most_used_words(estadoVoc, estadoFeat)))\n",
    "print(\"\\nMais usadas no Globo: \\n {}\".format(show_most_used_words(globoVoc, globoFeat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos ver com mais clareza o conjunto de palavras mais utilizadas por cada jornal. Percebemos algumas características interessantes como:\n",
    "- Região principal do jornal: percebemos que a _Folha de São Paulo_ possui um forte foco na cidade de São Paulo, perceptível pelo grande número de menções ao prefeito João Doria. Já o jornal _O Globo_ possui 4 menções ao prefeito da cidade do Rio de Janeiro, Marcelo Crivella;\n",
    "- Trump: todos os jornais possuem menções do novo presidente dos EUA, Donald Trump, em alta recorrência. O _Estado de São Paulo_ tem inclusive maior recorrência de mencionar o Trump do que o atual presidente do Brasil, Michel Temer.\n",
    "- Odebrecht: Com a exceção do jornal _O Estado de São Paulo_, todos os jornais mencionam a Odebrecht em alta recorrência, graças às relações da empresa com propinas de políticos, assunto que está em alta no cenário político-jornalístico do Brasil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de valência mais recorrente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa seção, analisamos a valências médias por jornal. Para tanto, utilizaremos os resultados obtidos com a abordagem _Vader_, realizando a devida conversão para um formato mais amigável para a tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Globo Means: \n",
      "Neg: 0.13594444444444448, Pos: 0.0982063492063492, Neu:0.7658571428571429\n",
      "Valor Means: \n",
      "Neg: 0.09355084745762711, Pos: 0.08860169491525424, Neu:0.8178474576271186\n",
      "Folha Means: \n",
      "Neg: 0.19123622047244093, Pos: 0.09375590551181102, Neu:0.7150078740157482\n",
      "Estado Means: \n",
      "Neg: 0.13589922480620154, Pos: 0.1213798449612403, Neu:0.7427364341085271\n"
     ]
    }
   ],
   "source": [
    "vaderS = translatedDb.Vader_Score\n",
    "#A lambda function would be much better\n",
    "neg = []\n",
    "pos = []\n",
    "neu = []\n",
    "for score in vaderS:\n",
    "    neg.append(score['neg'])\n",
    "    pos.append(score['pos'])\n",
    "    neu.append(score['neu'])\n",
    "translatedDb['VaderNeg'] = neg\n",
    "translatedDb['VaderPos'] = pos\n",
    "translatedDb['VaderNeu'] = neu\n",
    "valor = translatedDb[translatedDb.Source=='\\'Valor\\'']\n",
    "folha = translatedDb[translatedDb.Source=='\\'Folha\\'']\n",
    "estado = translatedDb[translatedDb.Source == '\\'Estado\\'']\n",
    "globo = translatedDb[translatedDb.Source == '\\'Globo\\'']\n",
    "def get_means(db):\n",
    "    print(\"Neg: {0}, Pos: {1}, Neu:{2}\".format(db.VaderNeg.mean(), db.VaderPos.mean(), db.VaderNeu.mean()))\n",
    "print ('Globo Means: ')\n",
    "get_means(globo)\n",
    "print ('Valor Means: ')\n",
    "get_means(valor)\n",
    "print ('Folha Means: ')\n",
    "get_means(folha)\n",
    "print ('Estado Means: ')\n",
    "get_means(estado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados demonstram que o Valor é o jornal com manchetes com valência mais neutras e menos de positivas ou negativas. Por outro lado, a Folha de São Paulo é o jornal com o menor média de pontuação neutra e maior média de pontuação negativa. Já o jornal mais otimista é o Estado de São Paulo, mesmo considerando que a média de valências negativas é maior do que a de positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descobridor de jornal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos: \n",
      " 127 Manchetes da Folha \n",
      " 118 Manchetes do Valor \n",
      " 129 Manchetes do Estado\n",
      " 126 Manchetes do Globo\n"
     ]
    }
   ],
   "source": [
    "valor = originalDb[originalDb.Source=='\\'Valor\\'']\n",
    "folha = originalDb[originalDb.Source=='\\'Folha\\'']\n",
    "estado = originalDb[originalDb.Source == '\\'Estado\\'']\n",
    "globo = originalDb[originalDb.Source == '\\'Globo\\'']\n",
    "\n",
    "print ('Temos: \\n {0} Manchetes da Folha \\n {1} Manchetes do Valor \\n {2} Manchetes do Estado\\n {3} Manchetes do Globo'\n",
    "       .format(len(folha), len(valor), len(estado), len(globo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o número de manchetes de cada jornal está equilibrado, não precisamos tomar nenhum cuidado adicional nesse sentido. \n",
    "\n",
    "Vamos separar em conjuntos de treinamento e de teste, com 40% dos dados para teste e 60% para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(originalDb.Headline, originalDb.Source, test_size=0.4, random_state=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos montar nossos modelos. Utilizaremos novamente o countVectorizer para a separação das palavras, porém dessa vez também utilizaremos o algoritmo Tf-idf para obter a relevância de uma palavra em relação à coleção de palavras do documento e uma implementação de Naive Bayes multinomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o processo de adequação/treinamento, criaremos um pipeline com os três algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28499999999999998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test = X_test\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos um classificador com baixa performance relativa, embora este resultado esteja dentro do esperado ao considerarmos o tamanho do dataset de treinamento e de teste. \n",
    "Podemos tentar otimizar nosso classificador, utilizando busca extensiva de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.01\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1,3), (1,4), (1,5),\n",
    "                                   (2,1), (2,2), (2,3), (2,4)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3, 0.1, 0.0001, 0.5, 1),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "gs_clf.best_score_                                  \n",
    "for param_name in sorted(parameters.keys()):\n",
    "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32000000000000001"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                      ('clf', MultinomialNB(alpha=0.01)),\n",
    "])\n",
    "text_clf.fit(X_train, y_train) \n",
    "docs_test = X_test\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a otimização, percebemos que o ideal é utilizarmos conjuntos de 4 palavras por análise, **alpha** para Naive Bayes multinomial igual à 0.01 e algoritmo **idf**, obtendo assim precisão de 32%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amo o Dória']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.24333333  0.27333333  0.24666667  0.23666667]] \n",
      "\n",
      "['Dólar caro']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.87303683  0.03833311  0.04572673  0.04290333]] \n",
      "\n",
      "['Fracasso Lava Jato']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.44780194  0.36895537  0.1819543   0.00128839]] \n",
      "\n",
      "['desemprego sobe']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.11324043  0.06723401  0.81046446  0.0090611 ]] \n",
      "\n",
      "['violência sem limites']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.17501704  0.61424617  0.20066602  0.01007077]] \n",
      "\n",
      "['trump sucesso']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.39591828  0.21353699  0.29996875  0.09057598]] \n",
      "\n",
      "['temer lixo no brasil']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.22202333  0.02933653  0.00855506  0.74008508]] \n",
      "\n",
      "['T2 nota dez']\n",
      "[\"'Estado'\" \"'Folha'\" \"'Globo'\" \"'Valor'\"]\n",
      "[[ 0.82502964  0.06816217  0.01094132  0.09586686]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_source(docs_test):\n",
    "    predicted = text_clf.predict_proba(docs_test)\n",
    "    print(docs_test)\n",
    "    print(text_clf.classes_)\n",
    "    print(predicted, '\\n')\n",
    "headlines_test = [[\"Amo o Dória\"],\n",
    "                [\"Dólar caro\"], \n",
    "                [\"Fracasso Lava Jato\"], \n",
    "                [\"desemprego sobe\"],\n",
    "                [\"violência sem limites\"], \n",
    "                [\"trump sucesso\"],\n",
    "                [\"temer lixo no brasil\"],\n",
    "                [\"T2 nota dez\"]\n",
    "                 ]\n",
    "for headline in headlines_test:\n",
    "    find_source(headline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:textadventures]",
   "language": "python",
   "name": "conda-env-textadventures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
